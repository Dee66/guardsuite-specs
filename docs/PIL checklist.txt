PHASE 0 — AI IMPLEMENTOR RULES (MANDATORY)These rules are non-negotiable for the AI implementation phase:Never guess.Never generate placeholder logic or TODOs.Only produce the file specified in the instruction.Never modify or create additional files unless explicitly told.Use exact filenames and folder paths provided.Preserve comments and version fields in YAML.Validate YAML and Python syntax before outputting code.All Python must include required imports.Strictly follow the specification—no deviations.If any step is ambiguous, ask for clarification instead of inventing details.PHASE 1 — Establish Foundational PIL ContractsInstruction: For each item, create or update <repo_root>/<file_name> and output ONLY that file's content.scoring_kpis.ymlDefine KPI weighting fields: Implement score_weights as integers summing to 100 for composite scoring.Define task_type weights: Implement task_type_weights as floating-point multipliers (e.g., pipeline_stage: 1.0).Define gating rules: Implement gates as a list of strings referencing KPIs that, if failed, cap the total task score (e.g., TESTS_PASS prevents score $>50\%$).Add fields: Include a version field and a minimal, valid example block.repo_contract.ymlDefine sanity checks: Define the list of mandatory sanity_checks (e.g., product.yml exists, tests/ directory present).Define directory structure: Define the required_structure based on the GuardSuite Master Spec.Define complexity profile defaults: Implement the complexity_profile_metrics section, defining which structural metrics must be calculated (e.g., module_count, pipeline_stage_count).Include comments: Add descriptive comments for each field.project_map.ymlImplement schema: Use task_id as the root key for the task definition block.Implement linkages: Include task_source (referential) and dependencies (list of prerequisite task IDs).Implement assessment fields: Include implementation_files, validation_artifacts, and confidence_requirements (STATIC, DYNAMIC, AI_REVIEW).Pathing Convention: Specify clear pathing conventions using placeholders (e.g., src/<pillar_name>/...).task_contract.ymlDefine "done contract": Implement the done_contract as a list of binary requirements (e.g., implementation_files_present: true).Include ambiguity flags: Include the ambiguity_flags field, initialized as an empty list.Provide examples: Include clear examples for different task types (e.g., a pipeline_stage task vs. a documentation task).PHASE 2 — Build PIL Generator Engine (repo-scanner.py)Global Instruction: The Python script must be implemented as a class named PILScanner to manage state. All required imports (os, yaml, hashlib, ast, datetime, subprocess, json, etc.) must be at the top.Utility Functionscalculate_artifact_hash(file_path): Must use SHA-256 and safely handle FileNotFoundError by returning a predictable, stable sentinel value (e.g., MISSING_FILE_HASH) instead of throwing an exception.ast_check(file_path, required_signature):Must parse the AST and walk the nodes.Must return a tuple: (is_compliant: bool, diagnostic_message: str).The diagnostic message must be precise, detailing the specific AST node violation (e.g., missing parameter, incorrect decorator).Pre-Scan Gatesrun_sanity_gate(): Must check repo_contract.yml and return a structured health object, never throwing exceptions.version_and_drift_detection(): Must compare current artifact hashes against the last recorded hashes to generate The Delta of changed tasks.check_dependencies(): Must check the repos_index to ensure upstream tasks are complete before scoring the current task.Scoring LoopInstruction: Implement the primary task iteration loop within the PILScanner class.Execution Order: Iterate tasks, evaluate done_contract entries, apply gates (to cap the score), and then apply task_type_weights (as a final multiplier).Output: The loop must return a dictionary of detailed task results.Spec Coverage & Health Checkscompute_spec_coverage(): Must compare product.yml and checklist.yml items against mapped items in project_map.yml to compute the Spec Coverage Ratio (e.g., 90%).compute_complexity_profile(): Must run the static counting logic (e.g., using ast and os.listdir) and populate the complexity dictionary.PHASE 3 — Master Index and AI IntegrationGenerate repos_index.yml (Master Index Aggregation)Instruction (Crucial): Implement a function aggregate_all_repos(repo_list) that iterates over a list of all 12 repository paths, executes the PILScanner for each, and aggregates the results into a single output file.Data Structure: The top level must be a dictionary keyed by the actual repo_name (e.g., vectorscan).Data Structure: The progress_history field must be generated as a string of ASCII block characters (e.g., " ▂▅█") representing historical scores.Finalize AI Contract (Interface Documentation)AI Input Contract: Document the required payload: Contracts (project_map.yml, etc.), Master Index (repos_index.yml), and The Delta (changed files/test reports only).AI Output Contract: Mandate the structured YAML/JSON output with these exact fields:analysis: Brief explanation of the progress gap.missing_transition: Specific lifecycle state blocked.semantic_violations: List of errors detected by the AST scanner.spec_coverage_delta: List of unmapped items found in the specs.recommendation: The next actionable step.confidence: The AI's self-assessed confidence score, penalized by ambiguity_flags.Instruction: Include the explicit "Do Not Guess" constraint in the prompt documentation.