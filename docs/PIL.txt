Project Specification: Project Intelligence Layer (PIL)Project Name: Project Intelligence Layer (PIL)Version: 1.0 (Canonical)Target Platform: GuardSuite Repositories (x12)Goal: To establish a deterministic, machine-auditable metadata layer that accurately scores project progress by transforming abstract requirements into verifiable facts, thereby calibrating AI assessment.1. PIL System Architecture and WorkflowThe PIL is a three-component system.PIL Contracts (Input): YAML files in each repository root that define the map, contracts, and scoring rules.PIL Generator (repo-scanner.py): A Python engine that performs static and semantic analysis against the contracts.Master Index & AI Integration (Output): The aggregated, high-truth data used for centralized reporting and constrained AI queries.2. PIL Data Contract Specification (Input Files)These files must be placed in the root of every GuardSuite pillar repository.2.1. Project Mapping Layer (project_map.yml)The primary manifest linking checklist items to code artifacts.task_id: The ID from checklist.yml (e.g., CORE-001).task_source: A referential pointer to the task's origin (e.g., checklist.yml: CORE-001, product.yml: pipeline.evaluator_pipeline).dependencies: A simple list of prerequisite task IDs (e.g., [INIT-001, CORE-001]), forming the Task Dependency Graph.implementation_files: List of source files.validation_artifacts: List of required test files, snapshots, or expected output schemas.confidence_requirements: Defines the required assessment method for the AI (STATIC, DYNAMIC, AI_REVIEW).task_spec_coverage: Tracks which sections of the specs are addressed by this task.2.2. Task Contract (task_contract.yml)Defines the explicit, machine-verifiable definition of "DONE" for each task type.task_type: Classification used for scoring weights (e.g., pipeline_stage, documentation).done_contract: A list of binary conditions required for $100\%$ completion:implementation_files_present (Verified by AST).tests_pass (Verified by targeted reports).state_transition_implemented (Verified by static analysis).dependency_fulfilled (Verified by DAG check).ambiguity_flags: Tags for specific code regions where complexity or overlap is known, used to penalize the AI's confidence score.2.3. Repository Contract (repo_contract.yml)Enforces structural and governance compliance.sanity_checks: Mandatory checks required for the Full-Repo Sanity Gate (e.g., product.yml exists, src/ directory present).required_structure: Definition of mandatory file patterns and directory names.complexity_profile_metrics: Defines which structural metrics must be tracked (e.g., module_count, pipeline_stage_count).2.4. Universal Scoring Model (scoring_kpis.yml)Defines consistent scoring logic across all 12 pillars.score_weights: Defines the percentage weight of each verifiable KPI (e.g., TESTS_PASS: 30, CODE_ARTIFACT_PRESENT: 20).task_type_weights: Multipliers applied based on task criticality (e.g., pipeline_stage: 1.0).gates: Defines mandatory KPIs that, if failed, prevent the task score from exceeding a predefined threshold (e.g., test failure caps score at $50\%$).3. System Specification: PIL Generator (repo-scanner.py)The Python engine responsible for all analysis and data generation.3.1. Pre-Scan and Utility Layercalculate_artifact_hash(file_path): Uses SHA-256 for change detection; must return a stable sentinel value for missing files.run_sanity_gate(): Executes repo_contract.yml checks. If UNHEALTHY, task scoring is blocked.version_and_drift_detection(): Compares artifact hashes against the last scan to identify The Delta (tasks requiring re-evaluation), enabling incremental updates.ast_check(file_path, required_signature): Semantic Analysis Engine. Uses Python's AST to verify function existence, correct signature, and presence of pipeline stage decorators, returning a (is_compliant, diagnostic_message) tuple.3.2. Core Analysis EngineDependency Fulfillment: Checks the Task Dependency Graph against the Master Index results to ensure prerequisites are met before scoring.Targeted Test Aggregation: Reads project_map.yml to query CI/pytest reports for only the specific test cases that validate the current task, not generic test failure status.Weighted Scoring: Executes the core scoring loop: verifies done_contract entries, applies gates, and then applies task_type_weights.Spec Coverage & Complexity: Calculates the Spec Coverage Ratio (mapped items vs. total items in specs) and computes the Complexity Profile metrics (module count, stage count).4. AI Integration and Output ContractThe structured data output used for reporting and constrained AI queries.4.1. Multi-Repo Master Index (repos_index.yml)The single, aggregated source of truth for all 12 pillars.repo_nameoverall_progress: The final weighted score (e.g., $95\%$).health_signals: Status of sanity checks, drift_detected, stale_tasks.artifact_age: Timestamp of last commit and last successful test run.complexity_profile: Structural metrics.progress_history: ASCII sparkline string of score over time (e.g., " ▂▅█").task_details: Itemized, weighted score and status for every task ID.4.2. Constrained AI Query (The Interface)Input Payload: Minimal—Contracts, Master Index, The Delta (changed files/test reports), and the specific code subset for the task under review.Prompt Constraint: Must include the "Do Not Guess" principle and explicitly state that the AI's analysis must be confined to the provided data.4.3. AI Output Contract (The Reporting Format)The AI must return analysis in a strict YAML/JSON structure:analysis: Brief summary of the progress gap.missing_transition: Specific lifecycle state blocked.semantic_violations: List of errors detected by the AST scanner (e.g., "Function signature violation").spec_coverage_delta: Unmapped items found in the specs.recommendation: The next concrete step for the developer.confidence: The AI's self-assessed confidence score, penalized by ambiguity_flags and other uncertainties.